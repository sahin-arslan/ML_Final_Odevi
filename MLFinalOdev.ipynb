{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAWPgV49gakznWXngRj8I5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahin-arslan/ML_Final_Odevi/blob/main/MLFinalOdev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Veri Seti**\n",
        "\n",
        "Pima kızılderilerine ait 5 yıllık tıbbi veriler içermektedir. Bu veriler ile diyabet bağlanğıçının tahmini konusunda çalışma yapacağız.\n",
        "\n",
        "İki sınıflı bir veri seti vardır elimizde. Yani sonuçumuz 1 yada 0 şekilindedir. Veriler homojen dağılmamıştır. Bazı eksik verilerin sıfır olarak kabul edildiği varsayılmaktadır.\n",
        "\n",
        "\n",
        "Veri setimizdeki alanlar:\n",
        "1.   NOTP : Gebelik sayısı\n",
        "2.   PGC : Oral glikoz tolerans testinde 2 saat plazma glikoz konsantrasyonu\n",
        "3.   DBP : Diyastolik kan basıncı (mm Hg)\n",
        "4.   TST : Triceps deri kıvrım kalınlığı (mm)\n",
        "5.   INS : 2 saat serum insülini (mu U/ml)\n",
        "6.   BMI : Vücut kitle indeksi (kg cinsinden ağırlık/(m cinsinden boy)^2).\n",
        "7.   DPF : Diyabet soyağacı fonksiyonu\n",
        "8.   Age : Yaş\n",
        "9.   CV : Sınıf değişkeni(0 veya 1) (Tahmin edilmek istenen değişken)\n",
        "\n",
        "\n",
        "\n",
        "Not : Veri setine kolon isimleri eklenmiştir."
      ],
      "metadata": {
        "id": "MAGyiPtoLhGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tSize atanan veri setine tüm algoritmalar için optimizasyon uygulayınız.**\n",
        "\n",
        "\n",
        "*   Normalizasyon işlemi için Min-Max yöntemini tercih ettik.\n",
        "*   Bağımlı ve bağımsız değişkenlerimizi ayrımlarını yaprak datasetlerimizi oluşturduk\n",
        "*   Eğitim ve test setlerimizi ayrıştırdık(%20 test)\n",
        "*   Model hiperparametlererini belirledik. Burada RandomForestRegressor'den yararlanıyoruz\n",
        "*   Grid Search kullanarak hiperparemater optimizasyonu uyguluyoruz.\n",
        "*   En iyi parametrelerimizi belirledikten sonra ekrana yazdırıyoruz.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zj7ENvqaz1q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Veri setini yüklüyoruz\n",
        "df = pd.read_csv('veri-seti.txt', sep=\"\\t\")\n",
        "\n",
        "# Eksik verileri kontrol ediyoruz(Null değer varmı buna bakıyoruz)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Normalizasyon\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Özellik ve hedef değişkenleri ayırıyoruz\n",
        "X = df_scaled.drop('CV', axis=1)\n",
        "y = df_scaled['CV']\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayırıyoruz\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#En İyi Parametreler:\n",
        "\n",
        "# Model ve Hiperparametreler\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Grid Search ile Hiperparametre Optimizasyonu yapıyoruz\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# En iyi parametreleri ekrana yazdırıyoruz\n",
        "print(f'\\nEn iyi parametre Listesi: {grid_search.best_params_}')\n",
        "\n",
        "# En iyi model ile tahmin yapıyoruz\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Model performansını değerlendiriyoruz\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'\\nMSE (Tahminlerin gerçek değerlerden ne kadar saptığı:): {mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK7O1dgFxMd5",
        "outputId": "641f9837-0ee2-429d-eadf-bee64ef1e6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTP    0\n",
            "PGC     0\n",
            "DBP     0\n",
            "TST     0\n",
            "INS     0\n",
            "BMI     0\n",
            "DPF     0\n",
            "Age     0\n",
            "CV      0\n",
            "dtype: int64\n",
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
            "\n",
            "En iyi parametre Listesi: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
            "\n",
            "MSE (Tahminlerin gerçek değerlerden ne kadar saptığı:): 0.16973497650428213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sonuçların yorumlanması**\n",
        "Paremetre listesini kullanarak en iyi performans için parametrelerimizi aşağıdaki gibi belirledik. Herbir kalemde ilgili parametreye ait açıklamayı aşağıda ekledik.\n",
        "\n",
        "Parametreler:\n",
        "\n",
        "1.   max_depth : None (olarak çıktı bu da ağaçımızın büyüme konusunda bir sınır koymayacağımız anlamına geliyor.)\n",
        "2.   min_samples_leaf : 2 (Bir düğüm de bulunması gereken minimum dal sayısı)\n",
        "3.   min_samples_split: 10 (bir sonraki düğüme dallanmak için gerekli minumun öğe sayısı)\n",
        "4.   n_estimators: 50(oluşturulacak ağaç sayısı)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T9F4WwYm1NJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Veri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Eğitim veri seti için Naive bayes sınıflandırıcısını uygulayınız. Elde ettiğiniz sonucları raporlayınız.**"
      ],
      "metadata": {
        "id": "SiAiMzxYOAp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Hedef değişkeni ve bağımsız değişkenleri ayırın\n",
        "X = df.drop('CV', axis=1)\n",
        "y = df['CV']\n",
        "\n",
        "# Veri setini rastgele %70 eğitim %30 test olacak şekilde ayırın\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Naive Bayes sınıflandırıcısını oluşturun ve eğitin\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test verileri üzerinde tahmin yapın\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Sonuçları raporlayın\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Doğruluk:\", accuracy)\n",
        "print(\"\\nSınıflandırma Raporu:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm2R57nhON55",
        "outputId": "486300eb-3b5c-4771-de04-ebeb37165a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doğruluk: 0.7445887445887446\n",
            "\n",
            "Sınıflandırma Raporu:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.80       151\n",
            "           1       0.62      0.66      0.64        80\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.72      0.73      0.72       231\n",
            "weighted avg       0.75      0.74      0.75       231\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Genel Doğruluk** değerimiz\n",
        "    **0.74**'dir.\n",
        "      Diğer bir değişle modelinizin doğru tahmin etme yüzdesi yaklaşık %74. Bu, modelinizin test verileri üzerindeki tahminlerinin %74'ünün doğru olduğunu gösterir.\n",
        "\n",
        "**Sınıflandırma Raporu Ayrıntıları**\n",
        "\n",
        "\n",
        "1.   **Sınıf 0 (Negatif Sınıf)**\n",
        "    \n",
        "    Sınıf 0 diyabet başlanğıcı olmayan hastaları ifade etmektedir.\n",
        "\n",
        "  *   **Precision (Kesinlik): 0.82**\n",
        "    Modelimizin sınıf 0 için yaptığı pozitif tahminlerin %82'si doğru.\n",
        "\n",
        "  *   **Recall (Duyarlılık): 0.79** Gerçekten 0 olan yadi diyabet başlancığı olmayan hastaların %79'unu doğru olarak tahminliyoruz. Burada %21'lik bir hata durumumuz mevcut.\n",
        "\n",
        "  *   **F1-Score: 0.80** Diğer iki parametreden ayrı olarak F1 score'u diyabet başlanğıcı olmayan hastaların genel tamin konusundaki performansına ilişkin bilgi veriyor. Sınıf 0 için %80'lık bir başarı yüzdemiz var diyebiliriz.\n",
        "\n",
        "  \n",
        "2.   **Sınıf 1 (Pozitif Sınıf)**\n",
        "  \n",
        "  Sınıf 1 diyabet başlanğıcı olan hastaları ifade etmektedir.\n",
        "\n",
        "  *   **Precision (Kesinlik): 0.62** Modelimizin diyabet başlanğıcı olan hastalardaki tahmin yüzdemiz biraz daha düşük olduğu görülmektedir. Diyabet başlanğıcı olan hastaların %62'sini doğru olarak tamin edebiliyoruz. Buradaha hata payımızı biraz yüksek yanı %39 dir.\n",
        "\n",
        "  *   **Recall (Duyarlılık): 0.66** Gerçekten diyabet başlanğıcı olan hastalar için bu tahmin yüzdemizi ifade etmektedir. Buradaki başarı oranımız %66'ya denk gelmektedir.\n",
        "\n",
        "  *   **F1-Score: 0.64** Diyabet başlanğıcı hastların tahmin yüzdesinin genel olarak başarısını ifade etmektedir. Buradaki başarı oranımız %64 hata payımız ise %36 dir.\n",
        "\n",
        "\n",
        "\n",
        "**Genel Durum Değerlendirmesi**\n",
        "\n",
        "\n",
        "1.   **Accuracy (Doğruluk):0.74** Tüm veri seti üzerindeki genel tahmin başarı yüzdemizi ifade etmektedir. %74 oranında başarılı tahmin yaptığımızı söyleyebiliriz.\n",
        "2.   **Macro Average (Makro Ortalama):**\n",
        "\n",
        "  Precision: 0.72\n",
        "\n",
        "  Recall: 0.73\n",
        "  \n",
        "  F1-Score: 0.72\n",
        "\n",
        "  Makro ortalama, her iki sınıfın performansını eşit ağırlıkla alır ve ortalama performansı gösterir. Diğer bir değişle ortalama başarı yüzdemizi ifade etmektedir. Bu üç parametreyi öncesinde ayrıntılı olarak ifade ettik.\n",
        "\n",
        "\n",
        "3.   **Weighted Average (Ağırlıklı Ortalama):**\n",
        "\n",
        "  Precision: 0.75\n",
        "\n",
        "  Recall: 0.74\n",
        "\n",
        "  F1-Score: 0.75\n",
        "\n",
        "  Ağırlıklı ortalama, her sınıfın veri setindeki temsil oranına göre ağırlıklandırılarak hesaplanır. Diğer bir ifade ile veri seti üzerindeki veri dağılımı dikkate alınarak hesaplandığını ifade etmektedir.\n",
        "\n",
        "\n",
        " Precision ve recall değerleri arasında belirgin bir fark olduğu görülüyor. Sınıf 1 için precision ve recall değerleri, sınıf 0'a göre daha düşük. Bu, modelin sınıf 1'i sınıf 0'dan daha az iyi tanıdığı anlamına gelir. Yani diyabet başlanğızı olmayan hastaların tahmini konusunda modelimiz daha başarılı.\n",
        "\n",
        "\n",
        "  Sonuç olarak, modeliniz sınıf 0'ı(diyabet başlanğıcı olmayan hastalar) iyi bir şekilde tanırken, sınıf 1'de(diyabet başlanğıcı olan hastalar) performans düşüklüğü yaşıyor. Bu durum, modelin sınıf dengesizliği veya sınıf 1'e ait örneklerin daha az belirgin özelliklere sahip olmasından kaynaklanabilir. Bu nedenle, veri dengesizliği ile başa çıkmak ve modelin performansını artırmak için verilerin homojen dağılıma sahip olduğuna dikkat etmek gerekir."
      ],
      "metadata": {
        "id": "bwe_mZ6QQfDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **3.\tVeri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Eğitim veri seti için K-en yakın komşuluk sınıflandırıcısını uygulayınız. En iyi k değerini belirleyerek Elde ettiğiniz sonuçları raporlayınız.**  \n",
        "\n"
      ],
      "metadata": {
        "id": "bV8grHpvdGIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Bağımlı ve bağımsız değişlenlerin ayırıyoruz\n",
        "X = df.drop('CV', axis=1)\n",
        "y = df['CV']\n",
        "\n",
        "# Data'yı eğitim ve test seti olarak ayırıyoruz\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# k değerimiz için bir aralık belirliyoruz. k değerimiz 1 ile 20 arasında bir değer alacaktır.\n",
        "k_values = range(1, 21)\n",
        "\n",
        "# Her k değeri için doğruluk scorlarını saklamak adına bir liste oluşturuyoruz\n",
        "accuracy_scores = []\n",
        "\n",
        "# Her k değeri için KNeighborsClassifier oluşturuyor\n",
        "# Eğitim ve test veri ile modeli eğitiyoruz\n",
        "# Test veri setini kullanarak taminle yapıyoruz\n",
        "# Bu tahminler doğrultusunda dopruluk deperlerini hesaplayarak accuracy_scores listemize ekliyoruz.\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# En yüksek doğruluk değerine sahip k değerini buluyoruz.\n",
        "best_k = k_values[accuracy_scores.index(max(accuracy_scores))]\n",
        "\n",
        "print(f\"En iyi k değeri: {best_k}\")\n",
        "print(f\"En yüksek doğruluk değeri: {max(accuracy_scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FUzBmPKdLzI",
        "outputId": "fcf8473c-2a86-432d-e1df-a2eaa354b8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En iyi k değeri: 13\n",
            "En yüksek doğruluk değeri: 0.7445887445887446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**En İyi k Değeri : 13**\n",
        "\n",
        "En iyi k değeri 13 olduğunda, modelimizin performansı en yüksek seviyede olduğunu söyleyebiliriz. Bu, KNN algoritmasının, eğitim verilerindeki en yakın 13 komşuyu kullanarak en iyi sonucu verdiği anlamına geliyor.\n",
        "\n",
        "**En Yüksek Doğruluk: 0.7445887445887446**\n",
        "\n",
        "Modelinizin doğruluğu yaklaşık %74. Bu, test veri setinde modelin yaptığı tahminlerin %74'ünün doğru olarak tahmin ettiği anlamına gelir.\n",
        "\n",
        "**Değerlendirme**\n",
        "\n",
        "%74 doğruluk skoru iyi bir skor olarak nitelendirebiliriz ama bu oranı artırmak mümkün olabilir.\n",
        "\n",
        "\n",
        "KNN algoritması, yüksek boyutlu veri setlerinde performans kaybı yaşayabilir. Yani çok girdinin bulunduğu veri setlerini ifade etmektedir. Bizim veri setimizde toplam 8 tane girdi parametremiz bulunmaktadır. Bu durumda, özellik seçimi veya boyut indirgeme yöntemleri kullanarak performans artırabiliriz.\n",
        "Diğer bir değişle sonuçla kolerasyonu yüksek girdi parametrelerin kullanılması daha sağlıklı sonuçlar verecektir.\n",
        "\n",
        "\n",
        "Sonuç olarak, elde ettiğimiz sonuçlar doğrultusunda KNN modeli ile %74 doğruluk skorunu yakaladir diyebilirzi. En iyi performansı veren k değeri 13 olarak belirleyebildik."
      ],
      "metadata": {
        "id": "TvLzhYSYd-Mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.\tVeri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Eğitim veri seti için Multi-Layer Perceptron (MLP) ve Support Vector Machines (SVM) sınıflandırıcılarını uygulayınız. Eğitim ve test adımlarında elde ettiğiniz sonucları raporlayınız.**"
      ],
      "metadata": {
        "id": "BLz_k3B1fHVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Özelik ve hedef değişkenlerimizi ayırıyoruz\n",
        "X = df.drop('CV', axis=1)\n",
        "y = df['CV']\n",
        "\n",
        "# Eğitim, test veri setlerimizi ayırıyoruz. Test için %30'luk bir kısım ayırıyoruz\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# MLPClassifier kullanılarak bir MLP (Multilayer Perceptron) modeli oluşturuyoruz\n",
        "# Test ve eğitim veri testleri kullanarak modelimizi eğitiyoruz\n",
        "# Eğitimiz modelimizi test veri seti ile test ediyoruz. Yani taminleme yapıyoruz.\n",
        "# Son adımımızda yapılan taminleme sonuçları ile doğruluk skorunu hesaplıyoruz.\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "print(f\"MLP Doğruluk Skoru(Eğitim): {mlp.score(X_train, y_train)}\")\n",
        "print(f\"MLP Doğruluk Skoru(Test): {accuracy_mlp}\")\n",
        "\n",
        "# SVM kullanılarak bir SVM (Support Vector Machine) modeli oluşturuyoruz\n",
        "# Test ve eğitim veri testleri kullanarak modelimizi eğitiyoruz\n",
        "# Eğitimiz modelimizi test veri seti ile test ediyoruz. Yani taminleme yapıyoruz.\n",
        "# Son adımımızda yapılan taminleme sonuçları ile doğruluk skorunu hesaplıyoruz.\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"\\nSVM Doğruluk Skoru(Eğitim): {svm.score(X_train, y_train)}\")\n",
        "print(f\"SVM Doğruluk Skoru(Test): {accuracy_svm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl8ufjccfKI2",
        "outputId": "cb2dc395-c89e-4d7b-97e0-407fee370804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Doğruluk Skoru(Eğitim): 0.7914338919925512\n",
            "MLP Doğruluk Skoru(Test): 0.7229437229437229\n",
            "\n",
            "SVM Doğruluk Skoru(Eğitim): 0.7802607076350093\n",
            "SVM Doğruluk Skoru(Test): 0.7359307359307359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLPClassifier ve SVM modellerinin performanslarını inceleyerek karşılaştırmasını yapalım.\n",
        "\n",
        "**MLPClassifier (Multi-Layer Perceptron)**\n",
        "1.   **Training Accuracy (Eğitim Doğruluğu): 0.7914338919925512**\n",
        "\n",
        "    Modelimizin eğitim verisi üzerindeki doğruluk skorunu yaklaşık olarak %79'dur. Bu, modelimizin eğitim veri seti üzerinde yaptığı taminlemenin %79 doğru olduğu anlamına gelmektedir.\n",
        "\n",
        "\n",
        "2.  **Testing Accuracy (Test Doğruluğu): 0.7229437229437229**\n",
        "\n",
        "    Modelimizin test verisi üzerindeki doğruluk skorunu yaklaşık olarak %72'dur. Bu, modelimizin test veri seti üzerinde yaptığı taminlemenin %72 doğru olduğu anlamına gelmektedir.\n",
        "\n",
        "**SVM (Support Vector Machine)**\n",
        "\n",
        "\n",
        "1.   **Training Accuracy (Eğitim Doğruluğu): 0.7802607076350093**\n",
        "\n",
        "    Modelimizin eğitim verisi üzerindeki doğruluk skorunu yaklaşık olarak %78'dur. Bu, modelimizin eğitim veri seti üzerinde yaptığı taminlemenin %78 doğru olduğu anlamına gelmektedir.\n",
        "\n",
        "2.   **Testing Accuracy (Test Doğruluğu): 0.7359307359307359**\n",
        "\n",
        "    Modelimizin test verisi üzerindeki doğruluk skorunu yaklaşık olarak %73'dur. Bu, modelimizin test veri seti üzerinde yaptığı taminlemenin %73 doğru olduğu anlamına gelmektedir\n",
        "  \n",
        "**Karşılaştırma ve Değerlendirme**\n",
        "\n",
        "\n",
        "**Eğitim Doğruluğu**\n",
        "  *   MLP: %79\n",
        "  *   SVM: %78\n",
        "\n",
        "  Eğitim verisi üzerinde, MLPClassifier biraz daha yüksek bir doğruluğa sahip olduğunu görüyoruz. Bu, MLP modelinin eğitim seti üzerindeki tahminleme yeteneğinin daha iyi olduğunu söyleyebiliriz.\n",
        "\n",
        "**Test Doğruluğu**\n",
        "\n",
        "\n",
        "*   MLP: %72\n",
        "*   SVM: %73\n",
        "\n",
        "  Test verisi üzerinde, SVM modeli MLP modeline göre biraz daha yüksek bir doğruluk değerine sahip. Bu, SVM modelinin daha önce görmediği verileri biraz daha iyi tahminleme yeteneğine sahip olduğunu gösterir.\n",
        "\n",
        "\n",
        "Sonuç olarak, SVM modeli test verisi üzerinde biraz daha iyi performans gösteriyor. Buna ek olarak her iki modelin de performansının benzer olduğunu görüyoruz. Farklı algoritmalar ve optimizasyonlarla, daha yüksek doğruluk oranlarına ulaşabiliriz.\n"
      ],
      "metadata": {
        "id": "N1NHY9M0f0S5"
      }
    }
  ]
}