{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh9zMABDRl1MDdaG3A3H7I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahin-arslan/ML_Final_Odevi/blob/main/MLFinalOdev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tSize atanan veri setine tÃ¼m algoritmalar iÃ§in optimizasyon uygulayÄ±nÄ±z.**\n",
        "\n",
        "\n",
        "*   Normalizasyon iÅŸlemi iÃ§in Min-Max yÃ¶ntemini kullunÄ±yoruz\n",
        "*   BaÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸkenlerimizi ayÄ±rÄ±yoruz.\n",
        "*   EÄŸitim ve test setlerimizi ayÄ±rÄ±yoruz(%20 test)\n",
        "*   Model hiperparametlererini belirliyoruz. Burada RandomForestRegressor'den yararlanÄ±yoruz\n",
        "*   Grid Search kullanarak hiperparemater optimizasyonu yapÄ±yoruz.\n",
        "*   En iyi parametrelerimizi belirledikten sonra ekrana yazdÄ±rÄ±yoruz.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zj7ENvqaz1q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Veri setini yÃ¼kleyin\n",
        "df = pd.read_csv('veri-seti.txt', sep=\"\\t\")\n",
        "\n",
        "# Eksik verileri kontrol edin\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Normalizasyon\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Ã–zellik ve hedef deÄŸiÅŸkenleri ayÄ±rÄ±n\n",
        "X = df_scaled.drop('CV', axis=1)\n",
        "y = df_scaled['CV']\n",
        "\n",
        "# Veriyi eÄŸitim ve test setlerine ayÄ±rÄ±n\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#En Ä°yi Parametreler:\n",
        "\n",
        "# Model ve Hiperparametreler\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Grid Search ile Hiperparametre Optimizasyonu\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# En iyi parametreler\n",
        "print(f'\\nEn iyi parametre Listesi: {grid_search.best_params_}')\n",
        "\n",
        "# En iyi model ile tahmin yapma\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Model performansÄ±nÄ± deÄŸerlendirme\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'\\nMSE (Tahminlerin gerÃ§ek deÄŸerlerden ne kadar saptÄ±ÄŸÄ±:): {mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK7O1dgFxMd5",
        "outputId": "03a31124-a1c3-4e56-cf9b-ff788a2573a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTP    0\n",
            "PGC     0\n",
            "DBP     0\n",
            "TST     0\n",
            "INS     0\n",
            "BMI     0\n",
            "DPF     0\n",
            "Age     0\n",
            "CV      0\n",
            "dtype: int64\n",
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
            "\n",
            "En iyi parametre Listesi: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
            "\n",
            "MSE (Tahminlerin gerÃ§ek deÄŸerlerden ne kadar saptÄ±ÄŸÄ±:): 0.16973497650428213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SonuÃ§larÄ±n yorumlanmasÄ±**\n",
        "Paremetre listesini kullanarak en iyi performans iÃ§in parametrelerimizi aÅŸaÄŸÄ±daki gibi belirledik. Herbir kalemde ilgili parametreye ait aÃ§Ä±klamayÄ± aÅŸaÄŸÄ±da bulabilirsiniz.\n",
        "\n",
        "1.   max_depth : None (olarak Ã§Ä±ktÄ± bu da aÄŸaÃ§Ä±mÄ±zÄ±n bÃ¼yÃ¼me konusunda bir sÄ±nÄ±r koymayacaÄŸÄ±mÄ±z anlamÄ±na geliyor.)\n",
        "2.   min_samples_leaf : 2 (Bir dÃ¼ÄŸÃ¼m de bulunmasÄ± gereken minimum dal sayÄ±sÄ±)\n",
        "3.   min_samples_split: 10 (bir sonraki dÃ¼ÄŸÃ¼me dallanmak iÃ§in gerekli minumun Ã¶ÄŸe sayÄ±sÄ±)\n",
        "4.   n_estimators: 50(oluÅŸturulacak aÄŸaÃ§ sayÄ±sÄ±)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T9F4WwYm1NJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Veri setinizi rastgele olarak %70 eÄŸitim %30 test olacak ÅŸekilde ayÄ±rÄ±nÄ±z. EÄŸitim veri seti iÃ§in Naive bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± uygulayÄ±nÄ±z. Elde ettiÄŸiniz sonuclarÄ± raporlayÄ±nÄ±z.**"
      ],
      "metadata": {
        "id": "SiAiMzxYOAp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Hedef deÄŸiÅŸkeni ve baÄŸÄ±msÄ±z deÄŸiÅŸkenleri ayÄ±rÄ±n\n",
        "X = df.drop('CV', axis=1)\n",
        "y = df['CV']\n",
        "\n",
        "# Veri setini rastgele %70 eÄŸitim %30 test olacak ÅŸekilde ayÄ±rÄ±n\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± oluÅŸturun ve eÄŸitin\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test verileri Ã¼zerinde tahmin yapÄ±n\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# SonuÃ§larÄ± raporlayÄ±n\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"DoÄŸruluk:\", accuracy)\n",
        "print(\"\\nSÄ±nÄ±flandÄ±rma Raporu:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm2R57nhON55",
        "outputId": "e2a43985-31b3-473b-ab43-019013a1bc91"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoÄŸruluk: 0.7445887445887446\n",
            "\n",
            "SÄ±nÄ±flandÄ±rma Raporu:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.80       151\n",
            "           1       0.62      0.66      0.64        80\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.72      0.73      0.72       231\n",
            "weighted avg       0.75      0.74      0.75       231\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Genel DoÄŸruluk**\n",
        "  **DoÄŸruluk:**\n",
        "    **0.7445887445887446**\n",
        "      Modelinizin doÄŸruluÄŸu yaklaÅŸÄ±k %74. Bu, modelinizin test verileri Ã¼zerindeki tahminlerinin %74'Ã¼nÃ¼n doÄŸru olduÄŸunu gÃ¶sterir.\n",
        "\n",
        "**SÄ±nÄ±flandÄ±rma Raporu**\n",
        "\n",
        "  **SÄ±nÄ±f 0 (Negatif SÄ±nÄ±f)**\n",
        "\n",
        "    **Precision (Kesinlik): 0.82**\n",
        "    Modelinizin sÄ±nÄ±f 0 iÃ§in yaptÄ±ÄŸÄ± pozitif tahminlerin %82'si doÄŸru.\n",
        "    DiÄŸer bir deyiÅŸle, model 0 sÄ±nÄ±fÄ±nda %18 oranÄ±nda hata yapÄ±yor.\n",
        "\n",
        "  **Recall (DuyarlÄ±lÄ±k): 0.79**\n",
        "\n",
        "  GerÃ§ekten sÄ±nÄ±f 0 olan Ã¶rneklerin %79'unu doÄŸru bir ÅŸekilde tahmin ediyor.\n",
        "  Model, sÄ±nÄ±f 0 olan Ã¶rneklerin %21'ini kaÃ§Ä±rÄ±yor.\n",
        "\n",
        "  **F1-Score: 0.80**\n",
        "\n",
        "  Precision ve recall'un harmonik ortalamasÄ±. Bu deÄŸer, modelin sÄ±nÄ±f 0 iÃ§in genel performansÄ±nÄ± Ã¶zetler.\n",
        "\n",
        "**SÄ±nÄ±f 1 (Pozitif SÄ±nÄ±f)**\n",
        "  **Precision (Kesinlik): 0.62**\n",
        "\n",
        "  Modelinizin sÄ±nÄ±f 1 iÃ§in yaptÄ±ÄŸÄ± pozitif tahminlerin %62'si doÄŸru.\n",
        "  Bu, sÄ±nÄ±f 1 tahminlerinde %38 oranÄ±nda hata yapÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir.\n",
        "\n",
        "  **Recall (DuyarlÄ±lÄ±k): 0.66**\n",
        "\n",
        "  GerÃ§ekten sÄ±nÄ±f 1 olan Ã¶rneklerin %66'sÄ±nÄ± doÄŸru tahmin ediyor.\n",
        "  Model, sÄ±nÄ±f 1 olan Ã¶rneklerin %34'Ã¼nÃ¼ kaÃ§Ä±rÄ±yor.\n",
        "\n",
        "  **F1-Score: 0.64**\n",
        "  Precision ve recall'un harmonik ortalamasÄ±. Bu deÄŸer, modelin sÄ±nÄ±f 1 iÃ§in genel performansÄ±nÄ± Ã¶zetler.\n",
        "\n",
        "**Genel Performans**\n",
        "  **Accuracy (DoÄŸruluk):** 0.74\n",
        "  Genel doÄŸruluk, modelin tÃ¼m test verisi Ã¼zerindeki doÄŸruluk oranÄ±nÄ± gÃ¶sterir.\n",
        "\n",
        "  **Macro Average (Makro Ortalama):**\n",
        "  Precision: 0.72\n",
        "  Recall: 0.73\n",
        "  F1-Score: 0.72\n",
        "  Makro ortalama, her iki sÄ±nÄ±fÄ±n performansÄ±nÄ± eÅŸit aÄŸÄ±rlÄ±kla alÄ±r ve ortalama performansÄ± gÃ¶sterir.\n",
        "\n",
        "  **Weighted Average (AÄŸÄ±rlÄ±klÄ± Ortalama):**\n",
        "  Precision: 0.75\n",
        "  Recall: 0.74\n",
        "  F1-Score: 0.75\n",
        "  AÄŸÄ±rlÄ±klÄ± ortalama, her sÄ±nÄ±fÄ±n veri setindeki temsil oranÄ±na gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±larak hesaplanÄ±r.\n",
        "\n",
        "\n",
        "**Yorum ve Ã–neriler**\n",
        "  Dengesizlik: Precision ve recall deÄŸerleri arasÄ±nda belirgin bir fark var. SÄ±nÄ±f 1 iÃ§in precision ve recall deÄŸerleri, sÄ±nÄ±f 0'a gÃ¶re daha dÃ¼ÅŸÃ¼k. Bu, modelin sÄ±nÄ±f 1'i sÄ±nÄ±f 0'dan daha az iyi tanÄ±dÄ±ÄŸÄ± anlamÄ±na gelir.\n",
        "\n",
        "  **Model GeliÅŸtirme:**\n",
        "\n",
        "  Ã–zellik SeÃ§imi: Daha fazla Ã¶zellik eklemeyi veya mevcut Ã¶zellikleri iyileÅŸtirmeyi dÃ¼ÅŸÃ¼nebilirsiniz.\n",
        "  Veri DengesizliÄŸi: EÄŸer veri setinizde sÄ±nÄ±f dengesizliÄŸi varsa, bu durumu dengelemek iÃ§in Ã§eÅŸitli teknikler (SMOTE, class weighting) kullanabilirsiniz.\n",
        "  FarklÄ± Algoritmalar: FarklÄ± makine Ã¶ÄŸrenimi algoritmalarÄ±nÄ± (Random Forest, Support Vector Machine, XGBoost) deneyerek performansÄ± karÅŸÄ±laÅŸtÄ±rabilirsiniz.\n",
        "  Hiperparametre Optimizasyonu: Mevcut modelinizin hiperparametrelerini optimize ederek performansÄ± artÄ±rabilirsiniz.\n",
        "  SonuÃ§ olarak, modeliniz sÄ±nÄ±f 0'Ä± iyi bir ÅŸekilde tanÄ±rken, sÄ±nÄ±f 1'de performans dÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼ yaÅŸÄ±yor. Bu durum, modelin sÄ±nÄ±f dengesizliÄŸi veya sÄ±nÄ±f 1'e ait Ã¶rneklerin daha az belirgin Ã¶zelliklere sahip olmasÄ±ndan kaynaklanabilir. Bu nedenle, veri dengesizliÄŸi ile baÅŸa Ã§Ä±kmak ve modelin performansÄ±nÄ± artÄ±rmak iÃ§in yukarÄ±daki Ã¶nerilere baÅŸvurabilirsiniz."
      ],
      "metadata": {
        "id": "bwe_mZ6QQfDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **3.\tVeri setinizi rastgele olarak %70 eÄŸitim %30 test olacak ÅŸekilde ayÄ±rÄ±nÄ±z. EÄŸitim veri seti iÃ§in K-en yakÄ±n komÅŸuluk sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± uygulayÄ±nÄ±z. En iyi k deÄŸerini belirleyerek Elde ettiÄŸiniz sonuÃ§larÄ± raporlayÄ±nÄ±z.**  \n",
        "\n"
      ],
      "metadata": {
        "id": "bV8grHpvdGIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('CV', axis=1)\n",
        "y = df['CV']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define a range of k values to test\n",
        "k_values = range(1, 21)\n",
        "\n",
        "# Initialize lists to store accuracy scores for each k value\n",
        "accuracy_scores = []\n",
        "\n",
        "# Iterate through the k values and train the KNN classifier\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# Find the k value with the highest accuracy\n",
        "best_k = k_values[accuracy_scores.index(max(accuracy_scores))]\n",
        "\n",
        "# Print the results\n",
        "print(f\"Best k value: {best_k}\")\n",
        "print(f\"Highest accuracy: {max(accuracy_scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FUzBmPKdLzI",
        "outputId": "a13c0a88-6723-4456-a37d-d342f0bd78f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k value: 13\n",
            "Highest accuracy: 0.7445887445887446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SonuÃ§larÄ±n YorumlanmasÄ±**\n",
        "\n",
        "**En Ä°yi **\n",
        "**ğ‘˜**\n",
        "**k DeÄŸeri: 13**  \n",
        "\n",
        "ğ‘˜\n",
        "k deÄŸeri 13 olduÄŸunda, modelinizin performansÄ± en yÃ¼ksek seviyede. Bu, KNN algoritmasÄ±nÄ±n, eÄŸitim verilerindeki en yakÄ±n 13 komÅŸuyu kullanarak en iyi sonucu verdiÄŸi anlamÄ±na gelir.\n",
        "\n",
        "**En YÃ¼ksek DoÄŸruluk: 0.7445887445887446**\n",
        "\n",
        "Modelinizin doÄŸruluÄŸu yaklaÅŸÄ±k %74. Bu, test veri setinde modelin yaptÄ±ÄŸÄ± tahminlerin %74'Ã¼nÃ¼n doÄŸru olduÄŸu anlamÄ±na gelir.\n",
        "\n",
        "**DeÄŸerlendirme ve Ã–neriler**\n",
        "\n",
        "**Model PerformansÄ±:**\n",
        "\n",
        "%74 doÄŸruluk skoru, birÃ§ok makine Ã¶ÄŸrenimi problemi iÃ§in makul bir performans olarak deÄŸerlendirilebilir. Ancak, daha yÃ¼ksek doÄŸruluk oranlarÄ± elde etmek iÃ§in Ã§eÅŸitli iyileÅŸtirmeler yapÄ±labilir.\n",
        "\n",
        "**KNN AlgoritmasÄ±nÄ±n Ã–zellikleri:**\n",
        "\n",
        "KNN algoritmasÄ±, yÃ¼ksek boyutlu veri setlerinde performans kaybÄ± yaÅŸayabilir. Bu durumda, Ã¶zellik seÃ§imi veya boyut indirgeme yÃ¶ntemleri kullanarak performans artÄ±rÄ±labilir.\n",
        "KNN'nin performansÄ± ayrÄ±ca veri setindeki Ã¶rneklerin yoÄŸunluÄŸuna ve veri setindeki gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± da hassastÄ±r. Bu yÃ¼zden veri Ã¶n iÅŸleme adÄ±mlarÄ± Ã¶nemlidir.\n",
        "\n",
        "**DiÄŸer Modellerle KarÅŸÄ±laÅŸtÄ±rma:**\n",
        "\n",
        "KNN algoritmasÄ± dÄ±ÅŸÄ±nda, baÅŸka makine Ã¶ÄŸrenimi algoritmalarÄ± (Ã¶rneÄŸin, Decision Trees, Random Forests, SVM, Logistic Regression) kullanarak model performansÄ±nÄ±zÄ± karÅŸÄ±laÅŸtÄ±rabilirsiniz. Bu, en iyi modeli belirlemenize yardÄ±mcÄ± olabilir.\n",
        "\n",
        "**Hiperparametre Optimizasyonu:**\n",
        "\n",
        "KNN'nin\n",
        "ğ‘˜\n",
        "k parametresi dÄ±ÅŸÄ±nda, mesafe metriÄŸi gibi baÅŸka hiperparametrelerini de optimize edebilirsiniz. Bu, modelin performansÄ±nÄ± artÄ±rabilir.\n",
        "\n",
        "**K-Fold Ã‡apraz DoÄŸrulama:**\n",
        "\n",
        "Modelinizin doÄŸruluÄŸunu daha iyi deÄŸerlendirmek iÃ§in K-Fold Ã§apraz doÄŸrulama yÃ¶ntemini kullanabilirsiniz. Bu yÃ¶ntem, veri setini birden fazla kez bÃ¶lerek, modelin performansÄ±nÄ± daha genel bir ÅŸekilde deÄŸerlendirmenize olanak tanÄ±r.\n",
        "\n",
        "\n",
        "Ã–zetle, elde ettiÄŸiniz sonuÃ§lar doÄŸrultusunda KNN modeli ile %74 doÄŸruluk skoru yakalamÄ±ÅŸsÄ±nÄ±z. En iyi performansÄ± veren\n",
        "ğ‘˜\n",
        "k deÄŸeri 13 olarak belirlenmiÅŸ. Daha yÃ¼ksek performans elde etmek iÃ§in diÄŸer algoritmalarÄ± denemek ve modelin hiperparametrelerini optimize etmek faydalÄ± olabilir."
      ],
      "metadata": {
        "id": "TvLzhYSYd-Mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.\tVeri setinizi rastgele olarak %70 eÄŸitim %30 test olacak ÅŸekilde ayÄ±rÄ±nÄ±z. EÄŸitim veri seti iÃ§in Multi-Layer Perceptron (MLP) ve Support Vector Machines (SVM) sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±nÄ± uygulayÄ±nÄ±z. EÄŸitim ve test adÄ±mlarÄ±nda elde ettiÄŸiniz sonuclarÄ± raporlayÄ±nÄ±z.**"
      ],
      "metadata": {
        "id": "BLz_k3B1fHVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('CV', axis=1)\n",
        "y = df['CV']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# MLP Classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "print(f\"MLP Training Accuracy: {mlp.score(X_train, y_train)}\")\n",
        "print(f\"MLP Testing Accuracy: {accuracy_mlp}\")\n",
        "\n",
        "# SVM Classifier\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"SVM Training Accuracy: {svm.score(X_train, y_train)}\")\n",
        "print(f\"SVM Testing Accuracy: {accuracy_svm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl8ufjccfKI2",
        "outputId": "6054fe1e-8e49-47f1-f122-b8bc674e7409"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Training Accuracy: 0.7914338919925512\n",
            "MLP Testing Accuracy: 0.7229437229437229\n",
            "SVM Training Accuracy: 0.7802607076350093\n",
            "SVM Testing Accuracy: 0.7359307359307359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elde ettiÄŸiniz sonuÃ§larÄ± yorumlayarak, MLPClassifier ve SVM modellerinin performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±ralÄ±m:\n",
        "\n",
        "**MLPClassifier (Multi-Layer Perceptron)**\n",
        "â€¢\tTraining Accuracy (EÄŸitim DoÄŸruluÄŸu): 0.7914338919925512\n",
        "o\tModel, eÄŸitim verisi Ã¼zerinde yaklaÅŸÄ±k %79 doÄŸruluÄŸa sahip. Bu, modelin eÄŸitim verisindeki Ã¶rneklerin %79'unu doÄŸru bir ÅŸekilde sÄ±nÄ±flandÄ±rdÄ±ÄŸÄ± anlamÄ±na gelir.\n",
        "â€¢\tTesting Accuracy (Test DoÄŸruluÄŸu): 0.7229437229437229\n",
        "o\tModel, test verisi Ã¼zerinde yaklaÅŸÄ±k %72 doÄŸruluÄŸa sahip. Bu, modelin daha Ã¶nce gÃ¶rmediÄŸi test verisindeki Ã¶rneklerin %72'sini doÄŸru bir ÅŸekilde sÄ±nÄ±flandÄ±rdÄ±ÄŸÄ± anlamÄ±na gelir.\n",
        "\n",
        "**SVM (Support Vector Machine)**\n",
        "â€¢\tTraining Accuracy (EÄŸitim DoÄŸruluÄŸu): 0.7802607076350093\n",
        "o\tModel, eÄŸitim verisi Ã¼zerinde yaklaÅŸÄ±k %78 doÄŸruluÄŸa sahip.\n",
        "â€¢\tTesting Accuracy (Test DoÄŸruluÄŸu): 0.7359307359307359\n",
        "o\tModel, test verisi Ã¼zerinde yaklaÅŸÄ±k %73 doÄŸruluÄŸa sahip.\n",
        "\n",
        "**KarÅŸÄ±laÅŸtÄ±rma ve DeÄŸerlendirme**\n",
        "EÄŸitim DoÄŸruluÄŸu\n",
        "â€¢\tMLP: %79\n",
        "â€¢\tSVM: %78\n",
        "EÄŸitim verisi Ã¼zerinde, MLPClassifier biraz daha yÃ¼ksek bir doÄŸruluÄŸa sahip. Bu, MLP modelinin eÄŸitim verisindeki Ã¶rnekleri daha iyi Ã¶ÄŸrendiÄŸi anlamÄ±na gelebilir.\n",
        "\n",
        "**Test DoÄŸruluÄŸu**\n",
        "â€¢\tMLP: %72\n",
        "â€¢\tSVM: %73\n",
        "Test verisi Ã¼zerinde, SVM modeli MLP modeline gÃ¶re biraz daha yÃ¼ksek bir doÄŸruluÄŸa sahip. Bu, SVM modelinin daha Ã¶nce gÃ¶rmediÄŸi verileri biraz daha iyi genelleme yeteneÄŸine sahip\n"
      ],
      "metadata": {
        "id": "N1NHY9M0f0S5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g610UuMWf_He"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}